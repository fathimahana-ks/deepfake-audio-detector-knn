# ğŸ§ EchoScan â€“ Deepfake Audio Detection

A K-Nearest Neighbors (KNN)-based system to classify synthetic (deepfake) and real audio using Mel-Frequency Cepstral Coefficients (MFCCs).

---

## ğŸ” Overview

This project identifies whether an audio sample is real or AI-generated using:
- **K-Nearest Neighbors (KNN)** classifier
- **MFCC feature extraction**
- **Dataset of real and fake voices**
- **Audio preprocessing & segmentation**

---

## ğŸ§  Key Features

- ğŸ“Š **KNN Classification** with scikit-learn  
- ğŸµ **MFCC Extraction** using `librosa`  
- ğŸ”ˆ **10s Audio Segmentation** for dataset balancing  
- ğŸ“ Train/Test split with evaluation metrics  
- ğŸ“¦ Model saved using `joblib` for reuse  

---

## ğŸ“ Project Structure
The repository is organized as follows:<br><br>
`deepfake-audio-detector-knn/`<br>
â”‚<br>
â”œâ”€â”€ `notebooks/`<br>
â”‚â€ƒâ€ƒâ””â”€â”€ `deepfake_knn.ipynb`<br>
â”‚<br>
â”œâ”€â”€ `models/`<br>
â”‚â€ƒâ€ƒâ””â”€â”€ `knn_model.pkl`<br>
â”‚<br>
â”œâ”€â”€ `data/`<br>
â”‚â€ƒâ€ƒâ”œâ”€â”€ `AUDIO/`<br>
â”‚â€ƒâ€ƒâ”œâ”€â”€ `DATASET-balanced.csv`<br>
â”‚â€ƒâ€ƒâ””â”€â”€ `DEMONSTRATION/`<br>
â”‚<br>
â”œâ”€â”€ `scripts/`<br>
â”‚â€ƒâ€ƒâ””â”€â”€ `train_knn.py`<br>
â”‚<br>
â”œâ”€â”€ `requirements.txt`<br>
â”œâ”€â”€ `README.md`<br><br>


> Each folder and file is structured for clear navigation, efficient experimentation, and smooth model deployment.





---

## ğŸ› ï¸ Technologies Used

- Python
- Librosa
- Pydub
- Scikit-learn
- Matplotlib & Seaborn

---

## ğŸ“Š Evaluation Metrics

| Metric     | Value (Example) |
|------------|-----------------|
| Accuracy   | 92%             |
| Precision  | 90%             |
| Recall     | 93%             |
| F1-Score   | 91%             |

> ğŸ“Œ Confusion matrix and classification report are included in the `results/` folder.

---

## ğŸš€ How to Run

1. Clone this repo  
2. Install required packages:
   ```bash
   pip install -r requirements.txt

3. Run the Jupyter notebook or convert it to a Python script:

   ```bash
   jupyter notebook notebooks/deepfake_knn.ipynb

## ğŸ“¦ Model Deployment

Use the saved  model to make predictions on new audio features:

   ```bash
   import joblib
   
   model = joblib.load('models/knn_model.pkl')
   prediction = model.predict([your_features])
   print("Prediction:", prediction[0])
   ```
   
---

## ğŸ“Œ Notes

- The dataset requires balanced classes (equal number of fake and real audio clips).  
- Audio clips are segmented into fixed 10-second intervals.  
- Features are based on MFCCs for effective audio representation.  
- This project focuses on KNN; additional models (CNN, Naive Bayes) are in separate branches/repositories.  
- Make sure dependencies and data paths are properly configured for smooth execution.

---

## ğŸ“¬ Contact

**Fathima Hana**  
ğŸ“§ [fathimahanaks@gmail.com](mailto:fathimahanaks@gmail.com)  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/fathimahana/) 

Feel free to reach out for collaborations or questions!
