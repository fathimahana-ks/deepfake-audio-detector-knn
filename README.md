# ğŸ§ Deepfake Audio Detector - KNN

A K-Nearest Neighbors (KNN)-based system to classify synthetic (deepfake) and real audio using Mel-Frequency Cepstral Coefficients (MFCCs).

---

## ğŸ” Overview

This project identifies whether an audio sample is real or AI-generated using:
- **K-Nearest Neighbors (KNN)** classifier
- **MFCC feature extraction**
- **Dataset of real and fake voices**
- **Audio preprocessing & segmentation**

---

## ğŸ§  Key Features

- ğŸ“Š **KNN Classification** with scikit-learn  
- ğŸµ **MFCC Extraction** using `librosa`  
- ğŸ”ˆ **10s Audio Segmentation** for dataset balancing  
- ğŸ“ Train/Test split with evaluation metrics  
- ğŸ“¦ Model saved using `joblib` for reuse  

---

## ğŸ“ Project Structure
The repository is organized as follows:<br><br>
deepfake-audio-detector-knn/<br>
 â”‚<br>
 â”œâ”€â”€ notebooks/<br>
 â”‚ â””â”€â”€ deepfake_knn.ipynb<br>
 â”‚<br>
 â”œâ”€â”€ models/<br>
 â”‚ â””â”€â”€ knn_model.pkl<br>
 â”‚<br>
 â”œâ”€â”€ data/<br>
 â”‚ â”œâ”€â”€ AUDIO/<br>
 â”‚ â”œâ”€â”€ DATASET-balanced.csv<br>
 â”‚ â””â”€â”€ DEMONSTRATION/<br>
 â”‚<br>
 â”œâ”€â”€ requirements.txt<br>
 â”œâ”€â”€ README.md<br>
 â””â”€â”€ scripts/<br>
 â””â”€â”€ train_knn.py<br>

> Each folder and file is structured for clear navigation, efficient experimentation, and smooth model deployment.





---

## ğŸ› ï¸ Technologies Used

- Python
- Librosa
- Pydub
- Scikit-learn
- Matplotlib & Seaborn

---

## ğŸ“Š Evaluation Metrics

| Metric     | Value (Example) |
|------------|-----------------|
| Accuracy   | 92%             |
| Precision  | 90%             |
| Recall     | 93%             |
| F1-Score   | 91%             |

> ğŸ“Œ Confusion matrix and classification report are included in the `results/` folder.

---

## ğŸš€ How to Run

1. Clone this repo  
2. Install required packages:
   ```bash
   pip install -r requirements.txt

3. Run the Jupyter notebook or convert it to a Python script:

   ```bash
   jupyter notebook notebooks/deepfake_knn.ipynb

## ğŸ“¦ Model Deployment

Use the saved  model to make predictions on new audio features:

    ```bash
    import joblib
    
    model = joblib.load('models/knn_model.pkl')
    prediction = model.predict([your_features])
    print("Prediction:", prediction[0])
    ```
   
---

## ğŸ“Œ Notes

- The dataset requires balanced classes (equal number of fake and real audio clips).  
- Audio clips are segmented into fixed 10-second intervals.  
- Features are based on MFCCs for effective audio representation.  
- This project focuses on KNN; additional models (CNN, Naive Bayes) are in separate branches/repositories.  
- Make sure dependencies and data paths are properly configured for smooth execution.

---

## ğŸ“¬ Contact

**Fathima Hana**  
ğŸ“§ [fathimahanaks@gmail.com](mailto:fathimahanaks@gmail.com)  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/fathimahana/) 

Feel free to reach out for collaborations or questions!
